{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9316462,"sourceType":"datasetVersion","datasetId":5642866}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install  huggingface_hub","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-09-06T15:15:45.576389Z","iopub.execute_input":"2024-09-06T15:15:45.576758Z","iopub.status.idle":"2024-09-06T15:16:00.074936Z","shell.execute_reply.started":"2024-09-06T15:15:45.576718Z","shell.execute_reply":"2024-09-06T15:16:00.073805Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.24.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.7.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T15:24:44.751029Z","iopub.execute_input":"2024-09-06T15:24:44.751880Z","iopub.status.idle":"2024-09-06T15:24:45.055028Z","shell.execute_reply.started":"2024-09-06T15:24:44.751838Z","shell.execute_reply":"2024-09-06T15:24:45.054123Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b83ec202e5e40c2a09457841348eb93"}},"metadata":{}}]},{"cell_type":"code","source":"pip install accelerate","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install bitsandbytes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install auto-gptq\n!pip install --upgrade accelerate optimum transformers","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install git+https://github.com/huggingface/transformers","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip3 install torch --index-url https://download.pytorch.org/whl/cu118","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline, set_seed\nimport random\nimport os\nimport json\nimport time  # Import the time module\nimport torch  # Import torch to check for GPU availability\n\n# Hyperparameters\nMODEL_NAME = 'Qwen/Qwen2-1.5B-Instruct'\nDEVICE_MAP = 'auto'\nMAX_LENGTH = 200\nNUM_RETURN_SEQUENCES = 500\nOUTPUT_DIR = '/kaggle/working/LETTERS_batch02'\nTEXTDATA_DIR = '/kaggle/input/lines0012'  # Updated directory for topics and closing lines\nSAVE_INTERVAL = 1000  # Save letters after every 100 generations\n\n# Create the output directory if it doesn't exist\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# Check if GPU is available\nif torch.cuda.is_available():\n    device = \"GPU\"\nelse:\n    device = \"CPU\"\n\nprint(f\"Running on: {device}\")\n\n# Load the pre-trained model for text generation\ngenerator = pipeline(\n    'text-generation', \n    model=MODEL_NAME, \n    device_map=DEVICE_MAP, \n    torch_dtype=torch.float16, \n    trust_remote_code=True\n)\n\ndef read_lines_from_file(file_path):\n    \"\"\"Reads lines from a given text file and returns them as a list.\"\"\"\n    with open(file_path, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\ndef generate_custom_letter(prompt, max_length=MAX_LENGTH, num_return_sequences=NUM_RETURN_SEQUENCES, topics=None, closing_lines=None):\n    \"\"\"\n    Generates synthetic formal letters using a pre-trained language model.\n    \n    :param prompt: The initial text to start generating from.\n    :param max_length: The maximum length of the generated letter.\n    :param num_return_sequences: The number of letters to generate.\n    :param topics: A list of topics to randomly choose from for each letter generation.\n    :param closing_lines: A list of closing lines to randomly choose from for the letter.\n    :return: A list of tuples containing generated letters and the prompt used.\n    \"\"\"\n    letters = []\n    for _ in range(num_return_sequences):\n        # Set a new random seed for each letter generation\n        seed = random.randint(1, 100000000)\n        set_seed(seed)\n        \n        if topics:\n            topic = random.choice(topics)\n            if \": \" in topic:  # Check if the topic contains the expected format\n                subject = topic.split(\": \")[1]  # Extract the subject from the topic\n                # Prepare the prompt with subject and salutation\n                prompt_with_subject = f\"{prompt}\\n\\nSubject: {subject}\\n\\nDear [Recipient's Name],\\n\\n\"\n            else:\n                print(f\"Warning: Topic '{topic}' does not contain a valid format. Skipping.\")\n                continue  # Skip this iteration if the topic format is invalid\n        else:\n            prompt_with_subject = f\"{prompt}\\n\\nDear [Recipient's Name],\\n\\n\"\n        \n        # Generate the letter\n        letter = generator(\n            prompt_with_subject,\n            max_length=max_length,\n            num_return_sequences=1,\n            do_sample=True,\n            truncation=True\n        )[0]\n        text = letter['generated_text']\n        \n        # Add a random closing line\n        if closing_lines:\n            closing_line = random.choice(closing_lines)\n            # Append the closing line and sender's name after the main content\n            text += f\"\\n\\n{closing_line}\\n\\nSincerely,\\n\\n[Your Name]\"\n        \n        # Store the prompt and letter without additional details\n        letters.append((prompt_with_subject.strip(), f\"\\n\\n\\n{text.strip()}\"))  # Add a newline at the beginning of the letter\n    \n    return letters\n\ndef save_letters_to_json(letters, output_dir=OUTPUT_DIR):\n    \"\"\"\n    Saves each letter to a separate JSON file in the specified output directory.\n    \n    :param letters: A list of generated letters along with their letter counts.\n    :param output_dir: The directory where the JSON files will be saved.\n    \"\"\"\n    for i, (prompt, letter) in enumerate(letters):\n        filename = f\"letter_{i+1}.json\"\n        file_path = os.path.join(output_dir, filename)\n        \n        # Create a dictionary with the desired order\n        letter_data = {\n            \"prompt\": prompt,\n            \"output\": letter  # The letter now starts with a newline\n        }\n        \n        with open(file_path, 'w') as file:\n            json.dump(letter_data, file, indent=4)  # Use indent for pretty printing\n\n# Load topics and closing lines from text files\ntopics_file_path = os.path.join(TEXTDATA_DIR, 'topics.txt')\nclosing_lines_file_path = os.path.join(TEXTDATA_DIR, 'closing_lines.txt')\n\n# Read topics and closing lines from files\ntopics = read_lines_from_file(topics_file_path)\nclosing_lines = read_lines_from_file(closing_lines_file_path)\n\n# Define a new prompt based on the uploaded letter structure\nnew_prompt = \"\"\"\n[Your Name]\n[Your Address]\n[City, State, ZIP Code]\n[Email Address]\n[Phone Number]\n\n[Date]\n\n[Recipient's Name]\n[Recipient's Address]\n[City, State, ZIP Code]\n\"\"\"\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T17:28:13.156689Z","iopub.execute_input":"2024-09-06T17:28:13.157460Z","iopub.status.idle":"2024-09-06T17:28:17.545857Z","shell.execute_reply.started":"2024-09-06T17:28:13.157417Z","shell.execute_reply":"2024-09-06T17:28:17.544804Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Running on: GPU\n","output_type":"stream"}]},{"cell_type":"code","source":"# Generate synthetic letters with randomly chosen topics\nsynthetic_letters = generate_custom_letter(new_prompt, topics=topics, closing_lines=closing_lines)\n# Save the generated letters to individual JSON files\nfor i in range(0, len(synthetic_letters), SAVE_INTERVAL):\n    batch_letters = synthetic_letters[i:i+SAVE_INTERVAL]\n    save_letters_to_json(batch_letters)\n    print(f\"Saved letters {i+1} to {i+len(batch_letters)}\")\n    time.sleep(1)  # Add a short delay to avoid overloading the file system","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-09-06T17:28:21.908968Z","iopub.execute_input":"2024-09-06T17:28:21.909367Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport json\n\n# Directory where the letter files are stored\nLETTER_DIR = '/kaggle/working/LETTERS_batch02'\n\ndef check_letter_format(letter_data):\n    \"\"\"\n    Checks if the letter follows the expected format.\n    \n    :param letter_data: The letter data dictionary containing 'prompt' and 'output'.\n    :return: A list of format issues found in the letter.\n    \"\"\"\n    issues = []\n\n    # Check if the output starts with a newline\n    if not letter_data['output'].startswith('\\n'):\n        issues.append(\"Output does not start with a newline.\")\n\n    # Check if the prompt contains the necessary components\n    prompt_lines = letter_data['prompt'].strip().split('\\n')\n    if len(prompt_lines) < 6:\n        issues.append(\"Prompt is missing sender or recipient details.\")\n    \n    # Check for the subject line\n    if \"Subject:\" not in letter_data['prompt']:\n        issues.append(\"Prompt is missing a subject line.\")\n\n    # Check for the salutation\n    if \"Dear [Recipient's Name]\" not in letter_data['output']:\n        issues.append(\"Output is missing a salutation.\")\n\n    # Check for the closing line\n    if \"Sincerely,\" not in letter_data['output']:\n        issues.append(\"Output is missing a closing line.\")\n\n    return issues\n\ndef check_all_letters(directory):\n    \"\"\"\n    Checks all letter files in the specified directory for format compliance.\n    \n    :param directory: The directory containing the letter files.\n    \"\"\"\n    report = {}\n    \n    for filename in os.listdir(directory):\n        if filename.endswith('.json'):\n            file_path = os.path.join(directory, filename)\n            with open(file_path, 'r') as file:\n                letter_data = json.load(file)\n                \n                # Check the letter format\n                issues = check_letter_format(letter_data)\n                if issues:\n                    report[filename] = issues\n\n    return report\n\n# Run the check and print the report\nformat_report = check_all_letters(LETTER_DIR)\n\nif format_report:\n    print(\"The following files do not follow the correct format:\")\n    for file, issues in format_report.items():\n        print(f\"File: {file}\")\n        for issue in issues:\n            print(f\" - {issue}\")\nelse:\n    print(\"All letter files follow the correct format.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Directory where the files are stored\ndirectory = '/kaggle/working/LETTERS_batch02'\n\n# Count the number of files in the directory\nnum_files = len([f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))])\n\nprint(f\"Number of files in {directory}: {num_files}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n\n# Define the directory you want to download\nworking_dir = '/kaggle/working/LETTERS_batch02'\n# Define the name of the zip file\nzip_file_name = 'letters1.zip'\n# Define the output path for the zip file\noutput_path = f'/kaggle/working/{zip_file_name}'\n\n# Create a zip file of the directory\nshutil.make_archive(output_path.replace('.zip', ''), 'zip', working_dir)\n\nprint(f\"Zip file created: {output_path}\")\n\n# Now you can download the zip file from the Kaggle output section","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n\n# Specify the directory to delete\nkaggle_dir = '/kaggle/working/'\n\n# Check if the directory exists\nif os.path.exists(kaggle_dir):\n    # Delete the contents of the directory\n    for filename in os.listdir(kaggle_dir):\n        file_path = os.path.join(kaggle_dir, filename)\n        if os.path.isfile(file_path) or os.path.islink(file_path):\n            os.unlink(file_path)\n        elif os.path.isdir(file_path):\n            shutil.rmtree(file_path)\n    print(f\"Contents of {kaggle_dir} have been deleted.\")\nelse:\n    print(f\"{kaggle_dir} does not exist.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-06T17:28:01.349308Z","iopub.execute_input":"2024-09-06T17:28:01.349768Z","iopub.status.idle":"2024-09-06T17:28:01.358526Z","shell.execute_reply.started":"2024-09-06T17:28:01.349727Z","shell.execute_reply":"2024-09-06T17:28:01.357513Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Contents of /kaggle/working/ have been deleted.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}