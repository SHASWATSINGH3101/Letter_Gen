{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install  bitsandbytes transformers peft accelerate datasets scipy einops evaluate trl","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-09-08T19:29:28.217610Z","iopub.execute_input":"2024-09-08T19:29:28.217979Z","iopub.status.idle":"2024-09-08T19:29:50.206316Z","shell.execute_reply.started":"2024-09-08T19:29:28.217941Z","shell.execute_reply":"2024-09-08T19:29:50.205387Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nCollecting peft\n  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.33.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (1.14.0)\nCollecting einops\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nCollecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nCollecting trl\n  Downloading trl-0.10.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nCollecting tyro>=0.5.11 (from trl)\n  Downloading tyro-0.8.10-py3-none-any.whl.metadata (8.4 kB)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.1)\nCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\nDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.10.1-py3-none-any.whl (280 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.1/280.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.8.10-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nInstalling collected packages: shtab, einops, tyro, bitsandbytes, trl, peft, evaluate\nSuccessfully installed bitsandbytes-0.43.3 einops-0.8.0 evaluate-0.4.2 peft-0.12.0 shtab-1.7.1 trl-0.10.1 tyro-0.8.10\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom trl import SFTTrainer\nimport torch\nimport time\nimport pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-09-08T19:32:43.517478Z","iopub.execute_input":"2024-09-08T19:32:43.518498Z","iopub.status.idle":"2024-09-08T19:32:59.329210Z","shell.execute_reply.started":"2024-09-08T19:32:43.518438Z","shell.execute_reply":"2024-09-08T19:32:59.328244Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n\n# Load the base model with device_map set to 'auto'\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"SHASWATSINGH3101/Qwen2-0.5B-Instruct_lora_merge\",\n    device_map='auto'\n)\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"SHASWATSINGH3101/Qwen2-0.5B-Instruct_lora_merge\")\ntokenizer.pad_token = tokenizer.eos_token\n\ndef gen(model, p, maxlen=100, sample=True):\n    toks = tokenizer(p, return_tensors=\"pt\").to(model.device)  # Ensure tokens are on the same device as the model\n    res = model.generate(**toks, max_new_tokens=maxlen, do_sample=sample,\n                         num_return_sequences=1, temperature=0.1, num_beams=1, top_p=0.95)\n    return tokenizer.batch_decode(res, skip_special_tokens=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T19:33:30.682679Z","iopub.execute_input":"2024-09-08T19:33:30.683373Z","iopub.status.idle":"2024-09-08T19:33:32.943466Z","shell.execute_reply.started":"2024-09-08T19:33:30.683330Z","shell.execute_reply":"2024-09-08T19:33:32.942444Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"%%time\nseed = 42\nset_seed(seed)\n\nindex = 1\nprompt = \"Write a letter informing someone of potential legal action due to a dispute or violation.\"\nin_data = f\"Instruct: {prompt}\\n{prompt}\\nOutput:\\n\"\n\n# Generate response\npeft_model_res = gen(model, in_data, 259)\npeft_model_output = peft_model_res[0].split('Output:\\n')[1]\n\n# Extract the relevant parts of the output\nprefix, success, result = peft_model_output.partition('#End')\n\n# Print the results\ndash_line = '-' * 100\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{prompt}')\nprint(dash_line)\nprint(f'PEFT MODEL:\\n{prefix}')","metadata":{"execution":{"iopub.status.busy":"2024-09-08T19:33:56.001617Z","iopub.execute_input":"2024-09-08T19:33:56.002279Z","iopub.status.idle":"2024-09-08T19:34:06.229948Z","shell.execute_reply.started":"2024-09-08T19:33:56.002220Z","shell.execute_reply":"2024-09-08T19:34:06.228935Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------------------------------------------\nINPUT PROMPT:\nWrite a letter informing someone of potential legal action due to a dispute or violation.\n----------------------------------------------------------------------------------------------------\nPEFT MODEL:\n[Your Name]\n[Your Address]\n[City, State, ZIP Code]\n[Email Address]\n[Phone Number]\n\n[Date]\n\n[Recipient's Name]\n[Recipient's Address]\n[City, State, ZIP Code]\n\n\nSubject: Informing Someone of Potential Legal Action Due to a Dispute or Violation\n\nDear [Recipient's Name],\n\nI hope this letter finds you well. I am writing to inform you that there has been an issue involving my property, and it is important for me to take immediate action to address the situation.\n\nAs per our agreement, we have agreed upon the following steps:\n\n1. Immediate communication with your attorney regarding the matter\n2. Requested a meeting to discuss the situation further\n3. Provided all relevant documentation (e.g., photos, documents)\n\nHowever, as of now, I believe that there may be some issues with the process involved in resolving this matter. Specifically, I would like to request that you contact your local law enforcement department to report the incident to them immediately.\n\nPlease let me know if there are any other steps I need to take to resolve this matter. I appreciate your prompt attention to this matter and look forward to hearing from you soon.\n\nSincerely,\n\n[Your Name] \n\nNote: This is just a template and can be modified\nCPU times: user 10.2 s, sys: 0 ns, total: 10.2 s\nWall time: 10.2 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nseed = 42\nset_seed(seed)\n\nindex = 1\nprompt = \"Write a letter requesting a re-evaluation of your exam scores or grades.\"\nin_data = f\"Instruct: {prompt}\\n{prompt}\\nOutput:\\n\"\n\n# Generate response\npeft_model_res = gen(model, in_data, 259)\npeft_model_output = peft_model_res[0].split('Output:\\n')[1]\n\n# Extract the relevant parts of the output\nprefix, success, result = peft_model_output.partition('#End')\n\n# Print the results\ndash_line = '-' * 100\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{prompt}')\nprint(dash_line)\nprint(f'PEFT MODEL:\\n{prefix}')","metadata":{"execution":{"iopub.status.busy":"2024-09-08T19:33:05.521592Z","iopub.execute_input":"2024-09-08T19:33:05.522272Z","iopub.status.idle":"2024-09-08T19:33:17.096355Z","shell.execute_reply.started":"2024-09-08T19:33:05.522219Z","shell.execute_reply":"2024-09-08T19:33:17.095391Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------------------------------------------\nINPUT PROMPT:\nWrite a letter requesting a re-evaluation of your exam scores or grades.\n----------------------------------------------------------------------------------------------------\nPEFT MODEL:\n[Your Name]\n[Your Address]\n[City, State, ZIP Code]\n[Email Address]\n[Phone Number]\n\n[Date]\n\n[Recipient's Name]\n[Recipient's Address]\n[City, State, ZIP Code]\n\n\nSubject: Request for Re-Evaluation of Exam Scores/Grades\n\nDear [Recipient's Name],\n\nI hope this message finds you well. I am writing to request that my exam scores and/or grades be reviewed by the appropriate authority. As you may know, I have been taking [Course Name] at [University Name], and I would greatly appreciate it if you could provide me with an updated evaluation.\n\nMy current scores are as follows:\n\n- [Score 1]\n- [Score 2]\n- [Score 3]\n\nPlease let me know how we can proceed from here. Thank you in advance for your time and consideration.\n\nSincerely,\n\n[Your Name]\n\n**Note:** \n\n* Replace \"Your Name\" with your actual name\n* Replace \"Your Address\" with your mailing address\n* Replace \"Course Name\" with the name of the course\n* Replace \"University Name\" with the name of the university\n* Replace \"School Name\" with the school's name\n* Replace \"Name of the Course\" with the name of the course\n*\nCPU times: user 10.7 s, sys: 77.6 ms, total: 10.8 s\nWall time: 11.6 s\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}